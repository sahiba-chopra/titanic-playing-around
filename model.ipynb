{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahibachopra/miniconda/envs/ai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline, make_union\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/mnt/c/Users/sahib/Documents/Titanic Project/train.csv')\n",
    "test = pd.read_csv('/mnt/c/Users/sahib/Documents/Titanic Project/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = [train,test]\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    dataset['Title_Code'] = lb_make.fit_transform(dataset[\"Title\"])\n",
    "    # encode port of embarkment\n",
    "    dataset['Embarked_Code'] = lb_make.fit_transform(dataset[\"Embarked\"].astype(str))\n",
    "    # create 4 fare buckets\n",
    "    dataset['FareCat'] = pd.cut(dataset['Fare'], 4)\n",
    "    dataset['FareCat'] = lb_make.fit_transform(dataset[\"FareCat\"].astype(str))    \n",
    "    dataset['Has_Cabin'] = dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    # create 3 parch buckets\n",
    "    dataset['ParchCat'] = pd.cut(dataset['Parch'], 3)\n",
    "    dataset['ParchCat'] = lb_make.fit_transform(dataset[\"ParchCat\"].astype(str))\n",
    "    dataset['Sex'] = dataset['Sex'].map({\"male\":1,\"female\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature engineering\n",
    "features = [\"Sex\",\"Age\",\"Fare\",\"Pclass\",\"SibSp\",\"Parch\",\"Embarked_Code\"]\n",
    "X = train[features].copy()\n",
    "y = train[\"Survived\"]\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=1/3., random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With feature engineering\n",
    "features2 = [\"Sex\", \"Age\", \"FareCat\", \"IsAlone\", \"ParchCat\", \"Title_Code\",\"Pclass\",\"Embarked_Code\"]\n",
    "X_ = train[features2].copy()\n",
    "X_train2, X_validation2, y_train, y_validation = train_test_split(X_, y, test_size=1/3., random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/o feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8080808080808081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression - no feature engineering\n",
    "pipeline = Pipeline(steps = [\n",
    "        (\"features\", make_union(\n",
    "                make_pipeline(ColumnSelector([\"Pclass\",\"Sex\"]), OneHotEncoder()),\n",
    "                make_pipeline(ColumnSelector([\"Age\"]), \n",
    "                             Imputer(strategy=\"mean\"),\n",
    "                             StandardScaler()),\n",
    "                make_pipeline(ColumnSelector([\"Embarked_Code\"]),\n",
    "                             Imputer(strategy=\"most_frequent\"),\n",
    "                             OneHotEncoder()),\n",
    "                ColumnSelector([\"SibSp\",\"Parch\"]),\n",
    "                )),\n",
    "                (\"model\",LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pipeline.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8383838383838383"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "        (\"features\", make_union(\n",
    "                make_pipeline(ColumnSelector([\"Pclass\",\"Sex\",\"Title_Code\",\"ParchCat\",\"IsAlone\",\"FareCat\"]), OneHotEncoder()),\n",
    "                make_pipeline(ColumnSelector([\"Age\"]), \n",
    "                             Imputer(strategy=\"mean\"),\n",
    "                             StandardScaler()),\n",
    "                make_pipeline(ColumnSelector([\"Embarked_Code\"]),\n",
    "                             Imputer(strategy=\"most_frequent\"),\n",
    "                             OneHotEncoder()),\n",
    "                )),\n",
    "                (\"model\",LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train2, y_train)\n",
    "\n",
    "pipeline.score(X_validation2, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF w/o feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Score before CV: 0.797979797979798\n",
      "RF Score after CV: 0.8047138047138047\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "        (\"features\", make_union(\n",
    "                make_pipeline(ColumnSelector([\"Pclass\",\"Sex\"]), OneHotEncoder()),\n",
    "                make_pipeline(ColumnSelector([\"Age\"]), \n",
    "                             Imputer(strategy=\"mean\"),\n",
    "                             StandardScaler()),\n",
    "                make_pipeline(ColumnSelector([\"Embarked_Code\"]),\n",
    "                             Imputer(strategy=\"most_frequent\"),\n",
    "                             OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "                ColumnSelector([\"SibSp\",\"Parch\"]),\n",
    "                )),\n",
    "                (\"model\",RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"RF Score before CV: %s\" % pipeline.score(X_validation, y_validation))\n",
    "\n",
    "hyperparameters = { 'model__max_depth': [50, 70],\n",
    "                    'model__min_samples_leaf': [1,2]\n",
    "                  }\n",
    "\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"RF Score after CV: %s\" % clf.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF w/ feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Score before CV: 0.7946127946127947\n",
      "RF Score after CV: 0.8080808080808081\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "        (\"features\", make_union(\n",
    "                make_pipeline(ColumnSelector([\"Pclass\",\"Sex\",\"Title_Code\",\"ParchCat\",\"IsAlone\",\"FareCat\"]), OneHotEncoder()),\n",
    "                make_pipeline(ColumnSelector([\"Age\"]), \n",
    "                             Imputer(strategy=\"mean\"),\n",
    "                             StandardScaler()),\n",
    "                make_pipeline(ColumnSelector([\"Embarked_Code\"]),\n",
    "                             Imputer(strategy=\"most_frequent\"),\n",
    "                             OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "                )),\n",
    "                (\"model\",RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train2, y_train)\n",
    "\n",
    "print(\"RF Score before CV: %s\" % pipeline.score(X_validation2, y_validation))\n",
    "\n",
    "hyperparameters = { 'model__max_depth': [50, 70],\n",
    "                    'model__min_samples_leaf': [1,2]\n",
    "                  }\n",
    "\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "print(\"RF Score after CV: %s\" % clf.score(X_validation2, y_validation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
